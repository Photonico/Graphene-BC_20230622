-- Job Summary -------------------------------------------------------
Job Id: 7525802.pbsserver for user lniu6305 in queue normal
Job Name: job-name
Project: RDS-FSC-MOSHEMT-RW
Exit Status: 0
Job run as chunks (hpc146:ncpus=32:mem=104857600kb)+(hpc155:ncpus=32:mem=104857600kb)+(hpc150:ncpus=32:mem=104857600kb)
Walltime requested:  168:00:00 :      Walltime used:   79:06:10
                               :   Walltime percent:      47.1%
-- Nodes Summary -----------------------------------------------------
-- node hpc146 summary
    Cpus requested:         32 :          Cpus used:      31.83
          Cpu Time: 2517:29:15 :        Cpu percent:      99.5%
     Mem requested:    100.0GB :           Mem used:     39.8GB
                               :        Mem percent:      39.8%

-- node hpc155 summary
    Cpus requested:         32 :          Cpus used:      31.77
          Cpu Time: 2512:35:31 :        Cpu percent:      99.3%
     Mem requested:    100.0GB :           Mem used:     39.4GB
                               :        Mem percent:      39.4%

-- node hpc150 summary
    Cpus requested:         32 :          Cpus used:      31.78
          Cpu Time: 2512:40:11 :        Cpu percent:      99.3%
     Mem requested:    100.0GB :           Mem used:     39.3GB
                               :        Mem percent:      39.3%

-- WARNINGS ----------------------------------------------------------

** Low Walltime utilisation.  While this may be normal, it may help to check the
** following:
**   Did the job parameters specify more walltime than necessary? Requesting
**   lower walltime could help your job to start sooner.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application run more quickly than it should have? Is this analysis
**   the one you intended to run?
** 
** High CPU utilisation on hpc146.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc146. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc155.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc155. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc150.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc150. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
-- End of Job Summary ------------------------------------------------
