-- Job Summary -------------------------------------------------------
Job Id: 7533948.pbsserver for user lniu6305 in queue normal
Job Name: job-name
Project: RDS-FSC-MOSHEMT-RW
Exit Status: 0
Job run as chunks (hpc138:ncpus=32:mem=67108864kb)+(hpc175:ncpus=32:mem=67108864kb)
Walltime requested:   96:00:00 :      Walltime used:   30:00:03
                               :   Walltime percent:      31.3%
-- Nodes Summary -----------------------------------------------------
-- node hpc138 summary
    Cpus requested:         32 :          Cpus used:      31.39
          Cpu Time:  941:40:48 :        Cpu percent:      98.1%
     Mem requested:     64.0GB :           Mem used:     61.9GB
                               :        Mem percent:      96.8%

-- node hpc175 summary
    Cpus requested:         32 :          Cpus used:      31.48
          Cpu Time:  943:57:45 :        Cpu percent:      98.4%
     Mem requested:     64.0GB :           Mem used:     61.6GB
                               :        Mem percent:      96.2%

-- WARNINGS ----------------------------------------------------------

** Low Walltime utilisation.  While this may be normal, it may help to check the
** following:
**   Did the job parameters specify more walltime than necessary? Requesting
**   lower walltime could help your job to start sooner.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application run more quickly than it should have? Is this analysis
**   the one you intended to run?
** 
** High CPU utilisation on hpc138.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Excessive Memory utilisation on hpc138. While this may be normal, it may help to
** check the following:
**   Did the job parameters specify enough memory?
**   Did your analysis complete successfully, or did it run out of RAM?
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did the application use more memory than it should have? Is this analysis
**   the one you intended to run?
**
** High CPU utilisation on hpc175.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Excessive Memory utilisation on hpc175. While this may be normal, it may help to
** check the following:
**   Did the job parameters specify enough memory?
**   Did your analysis complete successfully, or did it run out of RAM?
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did the application use more memory than it should have? Is this analysis
**   the one you intended to run?
**
-- End of Job Summary ------------------------------------------------
