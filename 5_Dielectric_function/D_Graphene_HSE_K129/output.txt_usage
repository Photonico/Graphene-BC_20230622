-- Job Summary -------------------------------------------------------
Job Id: 7762611.pbsserver for user lniu6305 in queue large
Job Name: dielectric_Graphene_HSE
Project: RDS-FSC-MOSHEMT-RW
Exit Status: 0
Job run as chunks (hpc120:ncpus=32:mem=125829120kb)+(hpc124:ncpus=32:mem=125829120kb)+(hpc125:ncpus=32:mem=125829120kb)+(hpc126:ncpus=32:mem=125829120kb)
Walltime requested:  500:00:00 :      Walltime used:  499:41:09
                               :   Walltime percent:      99.9%
-- Nodes Summary -----------------------------------------------------
-- node hpc120 summary
    Cpus requested:         32 :          Cpus used:      31.18
          Cpu Time: 15580:34:50 :        Cpu percent:      97.4%
     Mem requested:    120.0GB :           Mem used:     49.5GB
                               :        Mem percent:      41.3%

-- node hpc124 summary
    Cpus requested:         32 :          Cpus used:      31.18
          Cpu Time: 15581:22:49 :        Cpu percent:      97.4%
     Mem requested:    120.0GB :           Mem used:     49.5GB
                               :        Mem percent:      41.2%

-- node hpc125 summary
    Cpus requested:         32 :          Cpus used:      31.21
          Cpu Time: 15597:37:05 :        Cpu percent:      97.5%
     Mem requested:    120.0GB :           Mem used:     49.5GB
                               :        Mem percent:      41.3%

-- node hpc126 summary
    Cpus requested:         32 :          Cpus used:      31.20
          Cpu Time: 15591:10:49 :        Cpu percent:      97.5%
     Mem requested:    120.0GB :           Mem used:     49.5GB
                               :        Mem percent:      41.2%

-- WARNINGS ----------------------------------------------------------

** Excessive Walltime utilisation.  While this may be normal, it may help to
** check the following:
**   Did the job parameters specify enough walltime?
**   Did your analysis complete successfully, or did it run out of time?
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run faster.
**   Did the application run more slowly than it should have? Is this analysis
**   the one you intended to run?
** 
** High CPU utilisation on hpc120.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc120. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc124.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc124. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc125.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc125. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc126.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc126. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
-- End of Job Summary ------------------------------------------------
