-- Job Summary -------------------------------------------------------
Job Id: 7603122.pbsserver for user lniu6305 in queue normal
Job Name: dielectric
Project: RDS-FSC-MOSHEMT-RW
Exit Status: 0
Job run as chunks (hpc150:ncpus=32:mem=125829120kb)+(hpc173:ncpus=32:mem=125829120kb)
Walltime requested:  100:00:00 :      Walltime used:   01:37:02
                               :   Walltime percent:       1.6%
-- Nodes Summary -----------------------------------------------------
-- node hpc150 summary
    Cpus requested:         32 :          Cpus used:      30.51
          Cpu Time:   49:20:21 :        Cpu percent:      95.3%
     Mem requested:    120.0GB :           Mem used:      4.6GB
                               :        Mem percent:       3.8%

-- node hpc173 summary
    Cpus requested:         32 :          Cpus used:      31.27
          Cpu Time:   49:45:04 :        Cpu percent:      97.7%
     Mem requested:    120.0GB :           Mem used:      4.5GB
                               :        Mem percent:       3.7%

-- WARNINGS ----------------------------------------------------------

** Low Walltime utilisation.  While this may be normal, it may help to check the
** following:
**   Did the job parameters specify more walltime than necessary? Requesting
**   lower walltime could help your job to start sooner.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application run more quickly than it should have? Is this analysis
**   the one you intended to run?
** 
** High CPU utilisation on hpc150.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc150. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc173.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc173. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
-- End of Job Summary ------------------------------------------------
