-- Job Summary -------------------------------------------------------
Job Id: 7611516.pbsserver for user lniu6305 in queue large
Job Name: dielectric
Project: RDS-FSC-MOSHEMT-RW
Exit Status: 0
Job run as chunks (hpc123:ncpus=32:mem=125829120kb)+(hpc127:ncpus=32:mem=125829120kb)+(hpc134:ncpus=32:mem=125829120kb)
Walltime requested:  200:00:00 :      Walltime used:  116:39:29
                               :   Walltime percent:      58.3%
-- Nodes Summary -----------------------------------------------------
-- node hpc123 summary
    Cpus requested:         32 :          Cpus used:      30.56
          Cpu Time: 3565:28:41 :        Cpu percent:      95.5%
     Mem requested:    120.0GB :           Mem used:     34.4GB
                               :        Mem percent:      28.7%

-- node hpc127 summary
    Cpus requested:         32 :          Cpus used:      30.46
          Cpu Time: 3553:28:55 :        Cpu percent:      95.2%
     Mem requested:    120.0GB :           Mem used:     34.1GB
                               :        Mem percent:      28.4%

-- node hpc134 summary
    Cpus requested:         32 :          Cpus used:      30.56
          Cpu Time: 3564:15:34 :        Cpu percent:      95.5%
     Mem requested:    120.0GB :           Mem used:     34.1GB
                               :        Mem percent:      28.4%

-- WARNINGS ----------------------------------------------------------

** Low Walltime utilisation.  While this may be normal, it may help to check the
** following:
**   Did the job parameters specify more walltime than necessary? Requesting
**   lower walltime could help your job to start sooner.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application run more quickly than it should have? Is this analysis
**   the one you intended to run?
** 
** High CPU utilisation on hpc123.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc123. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc127.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc127. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
** High CPU utilisation on hpc134.  This is often normal, however you might want
** to double-check if you need to request more cores or have misconfigured MPI
** if your jobs ran slower than expected.  It might help to check the following:
**   Did the job parameters specify enough cores? Requesting more cores could
**   help your job run faster.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could make your job to run faster without needing any more cores.
**   Did the application use more cores than it should have? Is this analysis
**   the one you intended to run?
**
** Low Memory utilisation on hpc134. While this may be normal, it may help to check
** the following:
**   Did the job parameters specify too much memory? Requesting less RAM could
**   help your job to start sooner.
**   Did you use MPI and was the work distributed correctly? Correcting this
**   could allow your job to run using less RAM in each chunk.
**   Did your analysis complete as expected or did it crash before completing?
**   Did the application use less RAM than it should have? Is this analysis the
**   one you intended to run?
**
-- End of Job Summary ------------------------------------------------
